# RL-Simulator
A simple Reinforcement Learning (RL) simulator focused on the Multi-Armed Bandit problem.
Initialize bandits, simulate multiple runs, and observe the winning bandit based on rewards over time.

ğŸš€ Features
Initialize Bandits: Define multiple bandits with custom reward settings.

Auto Run: Automatically simulate a defined number of pulls (e.g., 100 runs).

Track Results: See the result after each run.

Winning Bandit: Identify which bandit performed best after all runs.

ğŸ–¥ï¸ Deployment
This project is already deployed and accessible online.
ğŸ”—https://rl-simulator.onrender.com/)

ğŸ“š How It Works
Set Up Bandits: Initialize bandits with different reward probabilities or payout configurations.

Start Simulation: Choose the number of runs (e.g., 100) and start auto-running.

Monitor Results: Watch each run's output and track rewards.

Final Winner: After all runs, the bandit with the highest total reward is declared the winner.


ğŸ§  About Multi-Armed Bandits
Multi-Armed Bandit problems are foundational in Reinforcement Learning.
They model the trade-off between exploration (trying new options) and exploitation (choosing the best-known option).

In this simulator, each bandit represents a slot machine with unknown payout rates, and the goal is to maximize cumulative rewards over time.
